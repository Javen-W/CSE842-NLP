{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "6756ef2a-492d-4161-9a62-9134c32bd0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "import string\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d164ef87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\treebank.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "9c90fd9b-47d5-45c2-9af1-5f146fd57c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size, hidden_size)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        hidden = F.tanh(self.i2h(input) + self.h2h(hidden))\n",
    "        output = self.h2o(hidden)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "class RNN_2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.rnn = torch.nn.RNN(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            nonlinearity='relu',\n",
    "            batch_first=False\n",
    "        )\n",
    "        self.linear = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.rnn(x)[0]\n",
    "        x = self.linear(h)\n",
    "        return x\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        for layer in model.children():\n",
    "            if hasattr(layer, 'reset_parameters'):\n",
    "                layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a064372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(tp, fp, fn):\n",
    "    return (2 * tp) / (2 * tp + fp + fn)\n",
    "\n",
    "def precision_score(tp, fp):\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def accuracy_score(tp, fp, tn, fn):\n",
    "    return (tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "def recall_score(tp, fn):\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def flatten(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list += row\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "b166ec44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3914, 271, 106]) torch.Size([3914, 271])\n"
     ]
    }
   ],
   "source": [
    "all_categories = ['DET', 'NOUN', 'ADJ', 'VERB', 'ADP', '.', 'ADV', 'CONJ', 'PRT', 'PRON', 'NUM', 'X']\n",
    "embedding_size = 100\n",
    "feature_size = embedding_size + 6\n",
    "\n",
    "# prepare dataset\n",
    "tagged_sentences = nltk.corpus.treebank.tagged_sents(tagset='universal')\n",
    "all_sentences = []\n",
    "max_length = -1\n",
    "for sentence in tagged_sentences:\n",
    "    t_sentence = []\n",
    "    for (word, tag) in sentence:\n",
    "        t_sentence.append(word)\n",
    "        \n",
    "    if len(t_sentence) > max_length:\n",
    "        max_length = len(t_sentence)\n",
    "    all_sentences.append(t_sentence)\n",
    "\n",
    "# create word-embeddings\n",
    "embeddings = Word2Vec(\n",
    "    sentences=all_sentences,\n",
    "    vector_size=embedding_size,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "def feature_engineer(word):\n",
    "    w = np.concatenate((\n",
    "            embeddings.wv[word],\n",
    "            np.array([\n",
    "                word.isalpha(),  # alphabetic\n",
    "                \"-\" in word,\n",
    "                word.isdigit(),\n",
    "                word.islower(),\n",
    "                word.istitle(),\n",
    "                word.isupper(),\n",
    "            ]).astype(int)\n",
    "        )\n",
    "    )\n",
    "    return w\n",
    "\n",
    "# create feature/class tensors\n",
    "X = torch.zeros((len(all_sentences), max_length, feature_size))\n",
    "y = torch.zeros((len(all_sentences), max_length))\n",
    "print(X.size(), y.size())\n",
    "\n",
    "for i, sentence in enumerate(tagged_sentences):\n",
    "    s_len = len(sentence)\n",
    "    for j, (word, tag) in enumerate(sentence):\n",
    "        j_offset = max_length - (s_len - j)  # pre-pad\n",
    "        X[i, j_offset] = torch.from_numpy(feature_engineer(word))\n",
    "        y[i, j_offset] = torch.tensor([all_categories.index(tag)], dtype=torch.long)\n",
    "    \n",
    "# normalize tensors\n",
    "X = torch.nn.functional.normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "4f42b7de-bc7f-4a79-9692-096f9ef4a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_FOLDS = 5\n",
    "\n",
    "def run_cv(model, model_idx, cv):\n",
    "    results = []\n",
    "    k_fold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=777)\n",
    "    for k, (train_idx, test_idx) in enumerate(k_fold.split(X, y)):\n",
    "        \n",
    "        # reset parameters\n",
    "        model.reset_parameters()\n",
    "        criterion = cv['criterion']()\n",
    "        optimizer = cv['optimizer'](\n",
    "            model.parameters(),\n",
    "            lr=cv['lr'],\n",
    "        )\n",
    "        \n",
    "        # split fold into training & testing sets\n",
    "        X_train, y_train, X_test, y_test = X[train_idx], y[train_idx], X[test_idx], y[test_idx]\n",
    "\n",
    "        for epoch in range(cv['epoch']):\n",
    "            # train the model\n",
    "            loss = train(model, X_train, y_train, criterion, optimizer)\n",
    "            \n",
    "            # test the model\n",
    "            y_pred, loss = test(model, X_test, y_test, criterion)\n",
    "            \n",
    "            # evaluate the model\n",
    "            accuracy = float(torch.sum(y_pred == y_test) / y_test.nelement())\n",
    "            results.append({\n",
    "                'fold': k,\n",
    "                'epoch': epoch,\n",
    "                'loss': loss,\n",
    "                'accuracy': accuracy,\n",
    "                'model_id': model_idx,\n",
    "                'criterion': cv['criterion'].__name__,\n",
    "                'optimizer': cv['optimizer'].__name__,\n",
    "                'learning_rate': cv['lr'],\n",
    "                'n_hidden': cv['hidden'],\n",
    "                'max_epochs': cv['epoch'],\n",
    "            })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "e6a998bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, y_train, criterion, optimizer):\n",
    "    # set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Clear the gradient buffers of the optimized parameters.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Perform the forward pass of the model\n",
    "    output = model(X_train)\n",
    "\n",
    "    # Pick only the output corresponding to last sequence element (input is pre padded)\n",
    "    output = output[:, -1, :]\n",
    "    target = y_train[:, -1].long()\n",
    "    \n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "b4ee273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, X_test, y_test, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(X_test)\n",
    "        \n",
    "        y_pred = output.argmax(dim=2)\n",
    "\n",
    "        # Pick only the output corresponding to last sequence element (input is pre padded)\n",
    "        output = output[:, -1, :]\n",
    "        target = y_test[:, -1].long()\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "    return y_pred, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "263a196b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# model_idx=0, {'criterion': <class 'torch.nn.modules.loss.NLLLoss'>, 'epoch': 100, 'hidden': 64, 'lr': 0.001, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>}\n",
      "\n",
      "# model_idx=1, {'criterion': <class 'torch.nn.modules.loss.NLLLoss'>, 'epoch': 100, 'hidden': 64, 'lr': 0.001, 'optimizer': <class 'torch.optim.adam.Adam'>}\n",
      "\n",
      "# model_idx=2, {'criterion': <class 'torch.nn.modules.loss.NLLLoss'>, 'epoch': 100, 'hidden': 64, 'lr': 0.0001, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>}\n",
      "\n",
      "# model_idx=3, {'criterion': <class 'torch.nn.modules.loss.NLLLoss'>, 'epoch': 100, 'hidden': 64, 'lr': 0.0001, 'optimizer': <class 'torch.optim.adam.Adam'>}\n",
      "\n",
      "# model_idx=4, {'criterion': <class 'torch.nn.modules.loss.NLLLoss'>, 'epoch': 100, 'hidden': 128, 'lr': 0.001, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>}\n",
      "\n",
      "# model_idx=5, {'criterion': <class 'torch.nn.modules.loss.NLLLoss'>, 'epoch': 100, 'hidden': 128, 'lr': 0.001, 'optimizer': <class 'torch.optim.adam.Adam'>}\n",
      "\n",
      "# model_idx=6, {'criterion': <class 'torch.nn.modules.loss.NLLLoss'>, 'epoch': 100, 'hidden': 128, 'lr': 0.0001, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>}\n",
      "\n",
      "# model_idx=7, {'criterion': <class 'torch.nn.modules.loss.NLLLoss'>, 'epoch': 100, 'hidden': 128, 'lr': 0.0001, 'optimizer': <class 'torch.optim.adam.Adam'>}\n",
      "\n",
      "# model_idx=8, {'criterion': <class 'torch.nn.modules.loss.CrossEntropyLoss'>, 'epoch': 100, 'hidden': 64, 'lr': 0.001, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>}\n",
      "\n",
      "# model_idx=9, {'criterion': <class 'torch.nn.modules.loss.CrossEntropyLoss'>, 'epoch': 100, 'hidden': 64, 'lr': 0.001, 'optimizer': <class 'torch.optim.adam.Adam'>}\n",
      "\n",
      "# model_idx=10, {'criterion': <class 'torch.nn.modules.loss.CrossEntropyLoss'>, 'epoch': 100, 'hidden': 64, 'lr': 0.0001, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>}\n",
      "\n",
      "# model_idx=11, {'criterion': <class 'torch.nn.modules.loss.CrossEntropyLoss'>, 'epoch': 100, 'hidden': 64, 'lr': 0.0001, 'optimizer': <class 'torch.optim.adam.Adam'>}\n",
      "\n",
      "# model_idx=12, {'criterion': <class 'torch.nn.modules.loss.CrossEntropyLoss'>, 'epoch': 100, 'hidden': 128, 'lr': 0.001, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>}\n",
      "\n",
      "# model_idx=13, {'criterion': <class 'torch.nn.modules.loss.CrossEntropyLoss'>, 'epoch': 100, 'hidden': 128, 'lr': 0.001, 'optimizer': <class 'torch.optim.adam.Adam'>}\n",
      "\n",
      "# model_idx=14, {'criterion': <class 'torch.nn.modules.loss.CrossEntropyLoss'>, 'epoch': 100, 'hidden': 128, 'lr': 0.0001, 'optimizer': <class 'torch.optim.rmsprop.RMSprop'>}\n",
      "\n",
      "# model_idx=15, {'criterion': <class 'torch.nn.modules.loss.CrossEntropyLoss'>, 'epoch': 100, 'hidden': 128, 'lr': 0.0001, 'optimizer': <class 'torch.optim.adam.Adam'>}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run K-Folds Cross-Validation.\n",
    "\"\"\"\n",
    "\n",
    "# set the random seed\n",
    "torch.manual_seed(777)\n",
    "\n",
    "# define cross-validation search parameters\n",
    "cv_params = {\n",
    "    'criterion': [torch.nn.NLLLoss, torch.nn.CrossEntropyLoss],\n",
    "    'optimizer': [torch.optim.RMSprop, torch.optim.Adam],\n",
    "    'hidden': [64, 128],\n",
    "    'lr': [0.001, 0.0001], # list(np.logspace(-4, -2, num=3)),\n",
    "    'epoch': [100],\n",
    "}\n",
    "\n",
    "# run & evaluate each model configuration\n",
    "results = []\n",
    "for model_idx, cv in enumerate(list(ParameterGrid(cv_params))):\n",
    "    # debug\n",
    "    print(f\"# model_idx={model_idx}, {cv}\\n\")\n",
    "    \n",
    "    # define model\n",
    "    model = RNN_2(\n",
    "        input_size=feature_size,\n",
    "        hidden_size=cv['hidden'],\n",
    "        output_size=len(all_categories)\n",
    "    )\n",
    "\n",
    "    # run cross-validation & report results\n",
    "    results.append(\n",
    "        run_cv(\n",
    "            model=model,\n",
    "            model_idx=model_idx,\n",
    "            cv=cv,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "764b50dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.858403</td>\n",
       "      <td>0.912980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.132133</td>\n",
       "      <td>0.914644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.115744</td>\n",
       "      <td>0.912325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.347072</td>\n",
       "      <td>0.912617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.164448</td>\n",
       "      <td>0.913987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">15</th>\n",
       "      <th>0</th>\n",
       "      <td>2.500520</td>\n",
       "      <td>0.012220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.598292</td>\n",
       "      <td>0.011532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.649918</td>\n",
       "      <td>0.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.416424</td>\n",
       "      <td>0.918499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.676917</td>\n",
       "      <td>0.011018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   loss  accuracy\n",
       "model_id fold                    \n",
       "0        0    -0.858403  0.912980\n",
       "         1    -2.132133  0.914644\n",
       "         2    -1.115744  0.912325\n",
       "         3    -1.347072  0.912617\n",
       "         4    -1.164448  0.913987\n",
       "...                 ...       ...\n",
       "15       0     2.500520  0.012220\n",
       "         1     2.598292  0.011532\n",
       "         2     2.649918  0.017800\n",
       "         3     2.416424  0.918499\n",
       "         4     2.676917  0.011018\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyze run results\n",
    "df = pd.DataFrame.from_records(flatten(results)).set_index(['model_id'])\n",
    "# print(df)\n",
    "df.groupby(by=['model_id', 'fold'])[['loss', 'accuracy']].agg(\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd16338a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
